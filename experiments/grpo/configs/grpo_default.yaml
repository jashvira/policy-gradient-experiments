# Default GRPO configuration
# Based on hyperparameters provided in the specification

# GRPO algorithm parameters
n_grpo_steps: 200
rollout_batch_size: 256
group_size: 8
train_batch_size: 256  # On-policy: equals rollout_batch_size
epochs_per_rollout_batch: 1

# Generation/sampling
sampling_temperature: 1.0
sampling_min_tokens: 4
sampling_max_tokens: 512
sampling_top_p: 1.0

# Loss configuration
loss_type: "reinforce_with_baseline"
use_std_normalization: true
advantage_eps: 1.0e-6
cliprange: 0.2  # For grpo_clip loss type

# Optimization
learning_rate: 1.0e-5
lr: 1.0e-5
gradient_accumulation_steps: 128  # microbatch size is 2, will fit on H100
weight_decay: 0.0
adam_beta1: 0.9
adam_beta2: 0.95
adam_eps: 1.0e-8
grad_clip: 1.0

# Model and devices
model_name: ".models/Qwen2.5-Math-1.5B-Instruct"
train_device: "cuda:0"
eval_device: "cuda:1"

# Memory and performance
gpu_memory_utilization: 0.85
vllm_gpu_mem_utilization: 0.85

# Data and validation
data_path: null  # Will default to MATH dataset
val_every_grpo_steps: 10
val_rollout_batch_size: 128
val_samples: 1024
val_temperature: 0.0
val_top_p: 1.0
max_new_tokens: 1024

# Checkpointing and saving
save_dir: "./grpo_output"
save_at_end: true
save_every_grpo_steps: 50
val_log_dir: "logs/grpo_val_generations"

# Logging
project: "grpo-math"
run_name: "grpo-default"
wandb_entity: null
seed: 42

# Scheduler (inherited from base)
warmup_steps: 0
warmup_ratio: 0.0
lr_scheduler: "cosine"