[1mdiff --git a/experiments/grpo/configs/grpo_clip.yaml b/experiments/grpo/configs/grpo_clip.yaml[m
[1mindex 9396a5d..2bbd162 100644[m
[1m--- a/experiments/grpo/configs/grpo_clip.yaml[m
[1m+++ b/experiments/grpo/configs/grpo_clip.yaml[m
[36m@@ -2,16 +2,16 @@[m
 # Based on grpo_default with loss_type set to grpo_clip[m
 [m
 # GRPO algorithm parameters[m
[31m-n_grpo_steps: 200[m
[32m+[m[32mn_grpo_steps: 50[m
 rollout_batch_size: 256[m
[31m-group_size: 16[m
[31m-train_batch_size: 256  # On-policy: equals rollout_batch_size[m
[31m-epochs_per_rollout_batch: 1[m
[32m+[m[32mgroup_size: 8[m
[32m+[m[32mtrain_batch_size: 64  # On-policy: equals rollout_batch_size[m
[32m+[m[32mepochs_per_rollout_batch: 4[m
 [m
 # Generation/sampling[m
 sampling_temperature: 1.0[m
 sampling_min_tokens: 4[m
[31m-sampling_max_tokens: 512[m
[32m+[m[32msampling_max_tokens: 1024[m
 sampling_top_p: 1.0[m
 [m
 # Loss configuration[m
[36m@@ -21,13 +21,14 @@[m [madvantage_eps: 1.0e-6[m
 cliprange: 0.2  # For grpo_clip loss type[m
 [m
 # Optimization[m
[31m-learning_rate: 2.0e-5[m
[31m-lr: 2.0e-5[m
[31m-gradient_accumulation_steps: 128  # microbatch size is 2, will fit on H100[m
[32m+[m[32mlearning_rate: 1.0e-5[m
[32m+[m[32mlr: 1.0e-5[m
[32m+[m[32mgradient_accumulation_steps: 32  # microbatch size is 8 (256/32)[m
 weight_decay: 0.0[m
 adam_beta1: 0.9[m
 adam_beta2: 0.95[m
 adam_eps: 1.0e-8[m
[32m+[m[32madam_fused: true[m
 grad_clip: 1.0[m
 [m
 # Model and devices[m
[36m@@ -41,7 +42,7 @@[m [mvllm_gpu_mem_utilization: 0.85[m
 [m
 # Data and validation[m
 data_path: null  # Will default to MATH dataset[m
[31m-val_every_grpo_steps: 10[m
[32m+[m[32mval_every_grpo_steps: 5[m
 val_rollout_batch_size: 512[m
 val_samples: 1024[m
 val_temperature: 0.0[m
